{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Impressions](https://PixelServer20190423114238.azurewebsites.net/api/impressions/MachineLearningNotebooks/how-to-use-azureml/training-with-deep-learning/how-to-use-estimator/how-to-use-estimator.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Run Using Pytorch Estimator in Azure ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use Azure ML's PyTorch estimator to run our training script locally by using the conda environment created for the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure ML SDK Version:  1.17.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"scripts\")\n",
    "sys.path.append(\"scripts/cocoapi/PythonAPI/\")\n",
    "\n",
    "import azureml.core\n",
    "from azureml.core import Workspace, Experiment\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.dnn import PyTorch\n",
    "\n",
    "from dotenv import set_key, get_key, find_dotenv\n",
    "from utilities import get_auth, download_data\n",
    "\n",
    "import torch\n",
    "from scripts.XMLDataset import BuildDataset, get_transform\n",
    "from scripts.maskrcnn_model import get_model\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython.display import display\n",
    "\n",
    "# check core SDK version number\n",
    "print(\"Azure ML SDK Version: \", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_path = find_dotenv(raise_error_if_not_found=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first download the dataset that includes the images of store shelves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n",
      "Finished extracting.\n"
     ]
    }
   ],
   "source": [
    "data_file = \"Data.zip\"\n",
    "data_url = (\"https://bostondata.blob.core.windows.net/builddata/{}\".format(data_file))\n",
    "download_data(data_file, data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize workspace\n",
    "Let's load the existing workspace you created earlier in the Azure ML configuration notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProjektAzure\n",
      "ProjektAzure\n",
      "eastus\n"
     ]
    }
   ],
   "source": [
    "ws = Workspace.from_config(auth=get_auth(env_path))\n",
    "print(ws.name, ws.resource_group, ws.location, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an Azure ML experiment\n",
    "Let's create an experiment and give it a name. The script runs will be recorded under this experiment in Azure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(workspace=ws, name='torchvision')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use a train.py script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "import sys\n",
      "\n",
      "sys.path.append(\"./cocoapi/PythonAPI/\")\n",
      "\n",
      "import torch\n",
      "import argparse\n",
      "import utils\n",
      "from XMLDataset import BuildDataset, get_transform\n",
      "from maskrcnn_model import get_model\n",
      "from engine import train_one_epoch, evaluate\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    parser = argparse.ArgumentParser(description=\"PyTorch Object Detection Training\")\n",
      "    parser.add_argument(\n",
      "        \"--data_path\", default=\"./Data/\", help=\"the path to the dataset\"\n",
      "    )\n",
      "    parser.add_argument(\"--batch_size\", default=2, type=int)\n",
      "    parser.add_argument(\n",
      "        \"--epochs\", default=10, type=int, help=\"number of total epochs to run\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--workers\", default=4, type=int, help=\"number of data loading workers\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--learning_rate\", default=0.005, type=float, help=\"initial learning rate\"\n",
      "    )\n",
      "    parser.add_argument(\"--momentum\", default=0.9, type=float, help=\"momentum\")\n",
      "    parser.add_argument(\n",
      "        \"--weight_decay\",\n",
      "        default=0.0005,\n",
      "        type=float,\n",
      "        help=\"weight decay (default: 1e-4)\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--lr_step_size\", default=3, type=int, help=\"decrease lr every step-size epochs\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--lr_gamma\",\n",
      "        default=0.1,\n",
      "        type=float,\n",
      "        help=\"decrease lr by a factor of lr-gamma\",\n",
      "    )\n",
      "    parser.add_argument(\"--print_freq\", default=10, type=int, help=\"print frequency\")\n",
      "    parser.add_argument(\"--output_dir\", default=\"outputs\", help=\"path where to save\")\n",
      "    parser.add_argument(\"--anchor_sizes\", default=\"16\", type=str, help=\"anchor sizes\")\n",
      "    parser.add_argument(\n",
      "        \"--anchor_aspect_ratios\", default=\"1.0\", type=str, help=\"anchor aspect ratios\"\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--rpn_nms_thresh\",\n",
      "        default=0.7,\n",
      "        type=float,\n",
      "        help=\"NMS threshold used for postprocessing the RPN proposals\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--box_nms_thresh\",\n",
      "        default=0.5,\n",
      "        type=float,\n",
      "        help=\"NMS threshold for the prediction head. Used during inference\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--box_score_thresh\",\n",
      "        default=0.05,\n",
      "        type=float,\n",
      "        help=\"during inference only return proposals\"\n",
      "        \"with a classification score greater than box_score_thresh\",\n",
      "    )\n",
      "    parser.add_argument(\n",
      "        \"--box_detections_per_img\",\n",
      "        default=100,\n",
      "        type=int,\n",
      "        help=\"maximum number of detections per image, for all classes\",\n",
      "    )\n",
      "    args = parser.parse_args()\n",
      "\n",
      "data_path = args.data_path\n",
      "\n",
      "# use our dataset and defined transformations\n",
      "dataset = BuildDataset(data_path, get_transform(train=True))\n",
      "dataset_test = BuildDataset(data_path, get_transform(train=False))\n",
      "\n",
      "# split the dataset in train and test set\n",
      "indices = torch.randperm(len(dataset)).tolist()\n",
      "dataset = torch.utils.data.Subset(dataset, indices[:-100])\n",
      "dataset_test = torch.utils.data.Subset(dataset_test, indices[-100:])\n",
      "\n",
      "batch_size = args.batch_size\n",
      "workers = args.workers\n",
      "\n",
      "# define training and validation data loaders\n",
      "data_loader = torch.utils.data.DataLoader(\n",
      "    dataset,\n",
      "    batch_size=2,\n",
      "    shuffle=True,\n",
      "    num_workers=workers,\n",
      "    collate_fn=utils.collate_fn,\n",
      ")\n",
      "\n",
      "data_loader_test = torch.utils.data.DataLoader(\n",
      "    dataset_test,\n",
      "    batch_size=2,\n",
      "    shuffle=False,\n",
      "    num_workers=workers,\n",
      "    collate_fn=utils.collate_fn,\n",
      ")\n",
      "\n",
      "# our dataset has two classes only - background and out of stock\n",
      "num_classes = 2\n",
      "\n",
      "model = get_model(\n",
      "    num_classes,\n",
      "    args.anchor_sizes,\n",
      "    args.anchor_aspect_ratios,\n",
      "    args.rpn_nms_thresh,\n",
      "    args.box_nms_thresh,\n",
      "    args.box_score_thresh,\n",
      "    args.box_detections_per_img,\n",
      ")\n",
      "\n",
      "# train on the GPU or on the CPU, if a GPU is not available\n",
      "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
      "\n",
      "# move model to the right device\n",
      "model.to(device)\n",
      "\n",
      "learning_rate = args.learning_rate\n",
      "momentum = args.momentum\n",
      "weight_decay = args.weight_decay\n",
      "\n",
      "# construct an optimizer\n",
      "params = [p for p in model.parameters() if p.requires_grad]\n",
      "optimizer = torch.optim.SGD(\n",
      "    params, lr=learning_rate, momentum=momentum, weight_decay=weight_decay\n",
      ")\n",
      "\n",
      "lr_step_size = args.lr_step_size\n",
      "lr_gamma = args.lr_gamma\n",
      "\n",
      "# and a learning rate scheduler\n",
      "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
      "    optimizer, step_size=lr_step_size, gamma=lr_gamma\n",
      ")\n",
      "\n",
      "# number of training epochs\n",
      "num_epochs = args.epochs\n",
      "print_freq = args.print_freq\n",
      "\n",
      "for epoch in range(num_epochs):\n",
      "    # train for one epoch, printing every 10 iterations\n",
      "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=print_freq)\n",
      "    # update the learning rate\n",
      "    lr_scheduler.step()\n",
      "    # evaluate on the test dataset after every epoch\n",
      "    evaluate(model, data_loader_test, device=device)\n",
      "\n",
      "# save model\n",
      "if not os.path.exists(args.output_dir):\n",
      "    os.makedirs(args.output_dir)\n",
      "torch.save(model.state_dict(), os.path.join(args.output_dir, \"model_latest.pth\"))\n",
      "\n",
      "print(\"That's it!\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"scripts/train.py\", \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create A Pytorch Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we pick the number of epochs to run the training for.This deliberately has a low default value for the speed of running. In actual application, set this to higher values (i.e. num_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 'use_docker' parameter will be deprecated. Please use 'environment_definition' instead.\n"
     ]
    }
   ],
   "source": [
    "script_params = {\n",
    "    \"--data_path\": \".\",\n",
    "    \"--workers\": 8,\n",
    "    \"--learning_rate\": 0.005,\n",
    "    \"--epochs\": num_epochs,\n",
    "    \"--anchor_sizes\": \"16,32,64,128,256,512\",\n",
    "    \"--anchor_aspect_ratios\": \"0.25,0.5,1.0,2.0\",\n",
    "    \"--rpn_nms_thresh\": 0.5,\n",
    "    \"--box_nms_thresh\": 0.3,\n",
    "    \"--box_score_thresh\": 0.10,\n",
    "}\n",
    "\n",
    "estimator = PyTorch(\n",
    "    source_directory=\"./scripts\",\n",
    "    script_params=script_params,\n",
    "    compute_target=\"local\",\n",
    "    entry_script=\"train.py\",\n",
    "    use_docker=False,\n",
    "    user_managed=True,\n",
    "    use_gpu=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we point the python interpreter to the local conda environment built for this tutorial. Azure ML SDK will run the training script using this environment. We also turn off project snapshot upload to the cloud since we have a large dataset in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.run_config.environment.python.interpreter_path = (\"/anaconda/envs/azureml_py36_pytorch/bin/python\")\n",
    "estimator.run_config.history.snapshot_project = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - If 'script' has been provided here and a script file name has been specified in 'run_config', 'script' provided in ScriptRunConfig initialization will take precedence.\n",
      "WARNING - If 'arguments' has been provided here and arguments have been specified in 'run_config', 'arguments' provided in ScriptRunConfig initialization will take precedence.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15558bce1f8a406ba4ef99262890795f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "_UserRunWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', '…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/torchvision/runs/torchvision_1608659833_6a87102a?wsid=/subscriptions/1db0a5ce-7de1-4082-8e25-3c5a4e5a9a98/resourcegroups/ProjektAzure/workspaces/ProjektAzure\", \"run_id\": \"torchvision_1608659833_6a87102a\", \"run_properties\": {\"run_id\": \"torchvision_1608659833_6a87102a\", \"created_utc\": \"2020-12-22T17:57:14.392844Z\", \"properties\": {\"_azureml.ComputeTargetType\": \"local\", \"ContentSnapshotId\": null, \"azureml.git.repository_uri\": \"https://github.com/ispmor/azure-project.git\", \"mlflow.source.git.repoURL\": \"https://github.com/ispmor/azure-project.git\", \"azureml.git.branch\": \"main\", \"mlflow.source.git.branch\": \"main\", \"azureml.git.commit\": \"0cd15c57f57b5894818909867bd32604aa9d5ad1\", \"mlflow.source.git.commit\": \"0cd15c57f57b5894818909867bd32604aa9d5ad1\", \"azureml.git.dirty\": \"True\"}, \"tags\": {\"mlflow.source.type\": \"JOB\", \"mlflow.source.name\": \"train.py\"}, \"script_name\": null, \"arguments\": null, \"end_time_utc\": \"2020-12-22T18:06:31.563373Z\", \"status\": \"Completed\", \"log_files\": {\"azureml-logs/60_control_log.txt\": \"https://projektastorage1d32b8c8a.blob.core.windows.net/azureml/ExperimentRun/dcid.torchvision_1608659833_6a87102a/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=eKvZjJXb5R9MR0QMF%2Fd%2ByurgoK6ijzqGvl7ju9zhpPo%3D&st=2020-12-22T17%3A56%3A38Z&se=2020-12-23T02%3A06%3A38Z&sp=r\", \"azureml-logs/70_driver_log.txt\": \"https://projektastorage1d32b8c8a.blob.core.windows.net/azureml/ExperimentRun/dcid.torchvision_1608659833_6a87102a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=4mFSFwZS5bkX7ufUMi9TQbOfyy8cGNnAKvfT2DsXE%2Bg%3D&st=2020-12-22T17%3A56%3A38Z&se=2020-12-23T02%3A06%3A38Z&sp=r\", \"logs/azureml/90027_azureml.log\": \"https://projektastorage1d32b8c8a.blob.core.windows.net/azureml/ExperimentRun/dcid.torchvision_1608659833_6a87102a/logs/azureml/90027_azureml.log?sv=2019-02-02&sr=b&sig=gec%2BhIClYm5eXqDesf11Gl3UjmHmGIFMgUii6CwkSlw%3D&st=2020-12-22T17%3A47%3A22Z&se=2020-12-23T01%3A57%3A22Z&sp=r\", \"logs/azureml/dataprep/python_span_745bbe04-4801-4aff-a002-23ebacd7fc9c.jsonl\": \"https://projektastorage1d32b8c8a.blob.core.windows.net/azureml/ExperimentRun/dcid.torchvision_1608659833_6a87102a/logs/azureml/dataprep/python_span_745bbe04-4801-4aff-a002-23ebacd7fc9c.jsonl?sv=2019-02-02&sr=b&sig=t99aeNlhGQMNSQaypaXtFtpsf1D5VmvencMznjDk8mQ%3D&st=2020-12-22T17%3A47%3A22Z&se=2020-12-23T01%3A57%3A22Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/60_control_log.txt\"], [\"azureml-logs/70_driver_log.txt\"], [\"logs/azureml/dataprep/python_span_745bbe04-4801-4aff-a002-23ebacd7fc9c.jsonl\"], [\"logs/azureml/90027_azureml.log\"]], \"run_duration\": \"0:09:17\"}, \"child_runs\": [], \"children_metrics\": {}, \"run_metrics\": [{\"name\": \"mAP@IoU=0.50\", \"run_id\": \"torchvision_1608659833_6a87102a\", \"categories\": [0], \"series\": [{\"data\": [0.9566988929770025]}]}], \"run_logs\": \"2020-12-22 17:57:17,161|azureml|DEBUG|Inputs:: kwargs: {'OutputCollection': True, 'EnableMLflowTracking': True, 'snapshotProject': False}, track_folders: None, deny_list: None, directories_to_watch: ['logs', 'logs/azureml']\\n2020-12-22 17:57:17,161|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Execution target type: none\\n2020-12-22 17:57:17,216|azureml.history._tracking.PythonWorkingDirectory|DEBUG|PySpark found in environment.\\n2020-12-22 17:57:17,217|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Pinning working directory for filesystems: ['pyfs']\\n2020-12-22 17:57:17,548|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2020-12-22 17:57:17,548|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveRunConfig'>\\n2020-12-22 17:57:17,548|azureml.core._experiment_method|DEBUG|Trying to register submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2020-12-22 17:57:17,548|azureml.core._experiment_method|DEBUG|Registered submit_function search, on method <class 'azureml.train.hyperdrive.runconfig.HyperDriveConfig'>\\n2020-12-22 17:57:17,548|azureml.core.run|DEBUG|Adding new factory <function HyperDriveRun._from_run_dto at 0x7fd3bcb1a510> for run source hyperdrive\\n2020-12-22 17:57:18,373|azureml.core.run|DEBUG|Adding new factory <function AutoMLRun._from_run_dto at 0x7fd3a285c8c8> for run source automl\\n2020-12-22 17:57:18,384|azureml.core.run|DEBUG|Adding new factory <function PipelineRun._from_dto at 0x7fd3bc82dd08> for run source azureml.PipelineRun\\n2020-12-22 17:57:18,393|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_reused_dto at 0x7fd3bc7ba7b8> for run source azureml.ReusedStepRun\\n2020-12-22 17:57:18,402|azureml.core.run|DEBUG|Adding new factory <function StepRun._from_dto at 0x7fd3bc7ba730> for run source azureml.StepRun\\n2020-12-22 17:57:18,411|azureml.core.run|DEBUG|Adding new factory <function ScriptRun._from_run_dto at 0x7fd3bcc9fe18> for run source azureml.scriptrun\\n2020-12-22 17:57:18,442|azureml.core.authentication.TokenRefresherDaemon|DEBUG|Starting daemon and triggering first instance\\n2020-12-22 17:57:18,449|azureml._restclient.clientbase|INFO|Created a worker pool for first use\\n2020-12-22 17:57:18,449|azureml.core.authentication|DEBUG|Time to expire 1814395.550137 seconds\\n2020-12-22 17:57:18,450|azureml._restclient.service_context|DEBUG|Created a static thread pool for ServiceContext class\\n2020-12-22 17:57:18,450|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 17:57:18,450|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 17:57:18,450|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 17:57:18,450|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 17:57:18,451|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 17:57:18,451|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 17:57:18,451|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 17:57:18,480|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2020-12-22 17:57:18,480|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2020-12-22 17:57:18,549|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2020-12-22 17:57:18,549|azureml._SubmittedRun#torchvision_1608659833_6a87102a|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': None, 'azureml.git.repository_uri': 'https://github.com/ispmor/azure-project.git', 'mlflow.source.git.repoURL': 'https://github.com/ispmor/azure-project.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': '0cd15c57f57b5894818909867bd32604aa9d5ad1', 'mlflow.source.git.commit': '0cd15c57f57b5894818909867bd32604aa9d5ad1', 'azureml.git.dirty': 'True'}\\n2020-12-22 17:57:18,549|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-12-22 17:57:19,070|azureml|DEBUG|Installed with mlflow version 1.11.0.\\n2020-12-22 17:57:19,070|azureml.mlflow|DEBUG|Setting up a Remote MLflow run\\n2020-12-22 17:57:19,073|azureml.mlflow|DEBUG|Creating a tracking uri in eastus.experiments.azureml.net for workspace /subscriptions/1db0a5ce-7de1-4082-8e25-3c5a4e5a9a98/resourceGroups/ProjektAzure/providers/Microsoft.MachineLearningServices/workspaces/ProjektAzure\\n2020-12-22 17:57:19,073|azureml.mlflow._internal.store|DEBUG|Initializing the AzureMLRestStore\\n2020-12-22 17:57:19,073|azureml.mlflow._internal.model_registry|DEBUG|Initializing the AzureMLflowModelRegistry\\n2020-12-22 17:57:19,073|azureml.mlflow|DEBUG|Setting MLflow tracking uri env var\\n2020-12-22 17:57:19,073|azureml.mlflow|DEBUG|Setting MLflow run id env var with torchvision_1608659833_6a87102a\\n2020-12-22 17:57:19,073|azureml.mlflow|DEBUG|Setting Mlflow experiment with torchvision\\n2020-12-22 17:57:19,074|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.type\\n2020-12-22 17:57:19,074|azureml.mlflow|DEBUG|Setting the mlflow tag mlflow.source.name\\n2020-12-22 17:57:19,075|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[START]\\n2020-12-22 17:57:19,075|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_details with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experiments/{experimentName}/runs/{runId}/details\\n2020-12-22 17:57:19,190|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.RunClient.get_details-async:False|DEBUG|[STOP]\\n2020-12-22 17:57:19,192|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[START]\\n2020-12-22 17:57:19,193|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling patch_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2020-12-22 17:57:19,280|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.RunClient.patch_by_exp_id-async:False|DEBUG|[STOP]\\n2020-12-22 17:57:19,280|azureml.WorkerPool|DEBUG|[START]\\n2020-12-22 17:57:19,280|azureml.SendRunKillSignal|DEBUG|[START]\\n2020-12-22 17:57:19,280|azureml.RunStatusContext|DEBUG|[START]\\n2020-12-22 17:57:19,280|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunContextManager.RunStatusContext|DEBUG|[START]\\n2020-12-22 17:57:19,280|azureml.MetricsClient|DEBUG|[START]\\n2020-12-22 17:57:19,280|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.MetricsClient|DEBUG|[START]\\n2020-12-22 17:57:19,280|azureml.ContentUploader|DEBUG|[START]\\n2020-12-22 17:57:19,281|azureml._history.utils.context_managers|DEBUG|starting file watcher\\n2020-12-22 17:57:19,281|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Start]\\n2020-12-22 17:57:19,281|azureml.TrackFolders|DEBUG|[START]\\n2020-12-22 17:57:19,281|azureml.WorkingDirectoryCM|DEBUG|[START]\\n2020-12-22 17:57:19,282|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[START]\\n2020-12-22 17:57:19,282|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/torchvision_1608659833_6a87102a\\n2020-12-22 17:57:19,282|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-12-22 17:57:19,282|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Storing working dir for pyfs as /tmp/azureml_runs/torchvision_1608659833_6a87102a\\n2020-12-22 17:57:19,288|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2020-12-22 17:57:19,288|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2020-12-22 17:57:19,960|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2020-12-22 17:57:19,988|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.torchvision_1608659833_6a87102a/logs/azureml/90027_azureml.log path: /tmp/azureml_runs/torchvision_1608659833_6a87102a/logs/azureml/90027_azureml.log\\n2020-12-22 17:57:20,014|azureml._history.utils.context_managers.FileWatcher|DEBUG|uploading data to container: azureml blob: ExperimentRun/dcid.torchvision_1608659833_6a87102a/logs/azureml/dataprep/python_span_745bbe04-4801-4aff-a002-23ebacd7fc9c.jsonl path: /tmp/azureml_runs/torchvision_1608659833_6a87102a/logs/azureml/dataprep/python_span_745bbe04-4801-4aff-a002-23ebacd7fc9c.jsonl\\n2020-12-22 17:57:20,015|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 17:57:20,015|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 17:57:20,015|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 0_result to queue of approximate size: 0\\n2020-12-22 17:57:48,444|azureml.core.authentication|DEBUG|Time to expire 1814365.556108 seconds\\n2020-12-22 17:57:50,020|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 17:57:50,021|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 17:57:50,021|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 1_result to queue of approximate size: 1\\n2020-12-22 17:58:18,444|azureml.core.authentication|DEBUG|Time to expire 1814335.555888 seconds\\n2020-12-22 17:58:20,022|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 17:58:20,022|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 17:58:20,022|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 2_result to queue of approximate size: 2\\n2020-12-22 17:58:48,444|azureml.core.authentication|DEBUG|Time to expire 1814305.555596 seconds\\n2020-12-22 17:58:50,024|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 17:58:50,024|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 17:58:50,024|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 3_result to queue of approximate size: 3\\n2020-12-22 17:59:18,444|azureml.core.authentication|DEBUG|Time to expire 1814275.555275 seconds\\n2020-12-22 17:59:20,026|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 17:59:20,026|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 17:59:20,027|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 4_result to queue of approximate size: 4\\n2020-12-22 17:59:48,445|azureml.core.authentication|DEBUG|Time to expire 1814245.554959 seconds\\n2020-12-22 17:59:50,028|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 17:59:50,028|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 17:59:50,028|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 5_result to queue of approximate size: 5\\n2020-12-22 18:00:18,445|azureml.core.authentication|DEBUG|Time to expire 1814215.554653 seconds\\n2020-12-22 18:00:20,030|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:00:20,030|azureml._history.utils.context_managers.FileWatcher.UploadQueue.6_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:00:20,030|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 6_result to queue of approximate size: 6\\n2020-12-22 18:00:48,445|azureml.core.authentication|DEBUG|Time to expire 1814185.554338 seconds\\n2020-12-22 18:00:50,032|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:00:50,032|azureml._history.utils.context_managers.FileWatcher.UploadQueue.7_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:00:50,033|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 7_result to queue of approximate size: 7\\n2020-12-22 18:01:18,446|azureml.core.authentication|DEBUG|Time to expire 1814155.554002 seconds\\n2020-12-22 18:01:20,034|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:01:20,035|azureml._history.utils.context_managers.FileWatcher.UploadQueue.8_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:01:20,035|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 8_result to queue of approximate size: 8\\n2020-12-22 18:01:30,038|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:01:30,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue.9_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:01:30,039|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 9_result to queue of approximate size: 9\\n2020-12-22 18:01:48,446|azureml.core.authentication|DEBUG|Time to expire 1814125.553676 seconds\\n2020-12-22 18:01:50,040|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:01:50,040|azureml._history.utils.context_managers.FileWatcher.UploadQueue.10_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:01:50,040|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 10_result to queue of approximate size: 10\\n2020-12-22 18:02:18,446|azureml.core.authentication|DEBUG|Time to expire 1814095.553353 seconds\\n2020-12-22 18:02:20,042|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:02:20,043|azureml._history.utils.context_managers.FileWatcher.UploadQueue.11_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:02:20,043|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 11_result to queue of approximate size: 11\\n2020-12-22 18:02:48,447|azureml.core.authentication|DEBUG|Time to expire 1814065.553 seconds\\n2020-12-22 18:02:50,044|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:02:50,045|azureml._history.utils.context_managers.FileWatcher.UploadQueue.12_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:02:50,045|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 12_result to queue of approximate size: 12\\n2020-12-22 18:03:18,447|azureml.core.authentication|DEBUG|Time to expire 1814035.552679 seconds\\n2020-12-22 18:03:20,049|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:03:20,049|azureml._history.utils.context_managers.FileWatcher.UploadQueue.13_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:03:20,049|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 13_result to queue of approximate size: 13\\n2020-12-22 18:03:48,447|azureml.core.authentication|DEBUG|Time to expire 1814005.55235 seconds\\n2020-12-22 18:03:50,051|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:03:50,052|azureml._history.utils.context_managers.FileWatcher.UploadQueue.14_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:03:50,055|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 14_result to queue of approximate size: 14\\n2020-12-22 18:04:00,056|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:04:00,057|azureml._history.utils.context_managers.FileWatcher.UploadQueue.15_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:04:00,057|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 15_result to queue of approximate size: 15\\n2020-12-22 18:04:18,448|azureml.core.authentication|DEBUG|Time to expire 1813975.551519 seconds\\n2020-12-22 18:04:20,058|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:04:20,063|azureml._history.utils.context_managers.FileWatcher.UploadQueue.16_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:04:20,063|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 16_result to queue of approximate size: 16\\n2020-12-22 18:04:30,064|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:04:30,064|azureml._history.utils.context_managers.FileWatcher.UploadQueue.17_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:04:30,064|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 17_result to queue of approximate size: 17\\n2020-12-22 18:04:48,448|azureml.core.authentication|DEBUG|Time to expire 1813945.551217 seconds\\n2020-12-22 18:04:50,068|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:04:50,068|azureml._history.utils.context_managers.FileWatcher.UploadQueue.18_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:04:50,068|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 18_result to queue of approximate size: 18\\n2020-12-22 18:05:18,449|azureml.core.authentication|DEBUG|Time to expire 1813915.5508 seconds\\n2020-12-22 18:05:20,070|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:05:20,071|azureml._history.utils.context_managers.FileWatcher.UploadQueue.19_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:05:20,071|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 19_result to queue of approximate size: 19\\n2020-12-22 18:05:48,450|azureml.core.authentication|DEBUG|Time to expire 1813885.550102 seconds\\n2020-12-22 18:05:50,073|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:05:50,074|azureml._history.utils.context_managers.FileWatcher.UploadQueue.20_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:05:50,074|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 20_result to queue of approximate size: 20\\n2020-12-22 18:06:18,450|azureml.core.authentication|DEBUG|Time to expire 1813855.550022 seconds\\n2020-12-22 18:06:20,076|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:06:20,076|azureml._history.utils.context_managers.FileWatcher.UploadQueue.21_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:06:20,076|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 21_result to queue of approximate size: 21\\n2020-12-22 18:06:25,063|azureml._restclient.service_context|DEBUG|Access an existing static threadpool for ServiceContext class\\n2020-12-22 18:06:25,063|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 18:06:25,064|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 18:06:25,064|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 18:06:25,064|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 18:06:25,064|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 18:06:25,064|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 18:06:25,064|azureml._base_sdk_common.service_discovery|DEBUG|Found history service url in environment variable AZUREML_SERVICE_ENDPOINT, history service url: https://eastus.experiments.azureml.net.\\n2020-12-22 18:06:25,094|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[START]\\n2020-12-22 18:06:25,094|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.RunClient|DEBUG|ClientBase: Calling get_by_exp_id with url /history/v1.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/experimentids/{experimentId}/runs/{runId}\\n2020-12-22 18:06:25,151|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.RunClient.get_by_exp_id-async:False|DEBUG|[STOP]\\n2020-12-22 18:06:25,151|azureml._SubmittedRun#torchvision_1608659833_6a87102a|DEBUG|Constructing run from dto. type: azureml.scriptrun, source: None, props: {'_azureml.ComputeTargetType': 'local', 'ContentSnapshotId': None, 'azureml.git.repository_uri': 'https://github.com/ispmor/azure-project.git', 'mlflow.source.git.repoURL': 'https://github.com/ispmor/azure-project.git', 'azureml.git.branch': 'main', 'mlflow.source.git.branch': 'main', 'azureml.git.commit': '0cd15c57f57b5894818909867bd32604aa9d5ad1', 'mlflow.source.git.commit': '0cd15c57f57b5894818909867bd32604aa9d5ad1', 'azureml.git.dirty': 'True'}\\n2020-12-22 18:06:25,152|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunContextManager|DEBUG|Valid logs dir, setting up content loader\\n2020-12-22 18:06:25,152|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.MetricsClient|DEBUG|Overrides: Max batch size: 50, batch cushion: 5, Interval: 1.\\n2020-12-22 18:06:25,152|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.PostMetricsBatchV2Daemon|DEBUG|Starting daemon and triggering first instance\\n2020-12-22 18:06:25,152|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.MetricsClient|DEBUG|Used <class 'azureml._common.async_utils.batch_task_queue.BatchTaskQueue'> for use_batch=True.\\n2020-12-22 18:06:25,787|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling pyfs\\n2020-12-22 18:06:25,787|azureml.history._tracking.PythonWorkingDirectory|INFO|Current working dir: /tmp/azureml_runs/torchvision_1608659833_6a87102a\\n2020-12-22 18:06:25,787|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Reverting working dir from /tmp/azureml_runs/torchvision_1608659833_6a87102a to /tmp/azureml_runs/torchvision_1608659833_6a87102a\\n2020-12-22 18:06:25,787|azureml.history._tracking.PythonWorkingDirectory|INFO|Working dir is already updated /tmp/azureml_runs/torchvision_1608659833_6a87102a\\n2020-12-22 18:06:25,787|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|[STOP]\\n2020-12-22 18:06:25,787|azureml.WorkingDirectoryCM|DEBUG|[STOP]\\n2020-12-22 18:06:25,787|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Uploading tracked directories: ['./outputs'], excluding ['azureml-logs/driver_log']\\n2020-12-22 18:06:25,787|azureml.history._tracking.PythonWorkingDirectory.workingdir|DEBUG|Calling track for pyfs\\n2020-12-22 18:06:25,787|azureml.history._tracking.PythonWorkingDirectory|DEBUG|./outputs exists as directory, uploading..\\n2020-12-22 18:06:25,787|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Found and adding path to upload: ./outputs/model_latest.pth\\n2020-12-22 18:06:25,787|azureml.history._tracking.PythonWorkingDirectory|DEBUG|Paths to upload is ['./outputs/model_latest.pth'] in dir ./outputs\\n2020-12-22 18:06:25,787|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Overriding default timeout to 300\\n2020-12-22 18:06:25,787|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Start]\\n2020-12-22 18:06:25,788|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[START]\\n2020-12-22 18:06:25,788|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient|DEBUG|ClientBase: Calling batch_create_empty_artifacts with url /artifact/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/artifacts/batch/metadata/{origin}/{container}\\n2020-12-22 18:06:26,071|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.batch_create_empty_artifacts-async:False|DEBUG|[STOP]\\n2020-12-22 18:06:26,071|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: perform_upload\\n2020-12-22 18:06:26,072|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:06:26,072|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Adding task 0_perform_upload to queue of approximate size: 0\\n2020-12-22 18:06:26,072|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|[Stop] - waiting default timeout\\n2020-12-22 18:06:26,072|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[START]\\n2020-12-22 18:06:26,072|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Overriding default flush timeout from None to 300\\n2020-12-22 18:06:26,072|azureml._restclient.clientbase|DEBUG|ClientBase: Calling create_blob_from_stream with url None\\n2020-12-22 18:06:26,073|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|Waiting 300 seconds on tasks: [AsyncTask(0_perform_upload)].\\n2020-12-22 18:06:26,153|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Start]\\n2020-12-22 18:06:26,153|azureml.BatchTaskQueueAdd_1_Batches.WorkerPool|DEBUG|submitting future: _handle_batch\\n2020-12-22 18:06:26,153|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Batch size 1.\\n2020-12-22 18:06:26,154|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:06:26,154|azureml._restclient.service_context.WorkerPool|DEBUG|submitting future: _log_batch_v2\\n2020-12-22 18:06:26,154|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|Adding task 0__handle_batch to queue of approximate size: 0\\n2020-12-22 18:06:26,154|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|[Stop] - waiting default timeout\\n2020-12-22 18:06:26,154|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.MetricsClient|DEBUG|Metrics Client: _log_batch_v2 is calling post_run_metrics posting 1 values.\\n2020-12-22 18:06:26,154|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[START]\\n2020-12-22 18:06:26,154|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2.0__log_batch_v2|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:06:26,155|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Overriding default flush timeout from None to 120\\n2020-12-22 18:06:26,155|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[START]\\n2020-12-22 18:06:26,155|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.MetricsClient.PostMetricsBatchV2|DEBUG|Adding task 0__log_batch_v2 to queue of approximate size: 0\\n2020-12-22 18:06:26,155|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0__handle_batch)].\\n2020-12-22 18:06:26,155|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.MetricsClient|DEBUG|ClientBase: Calling post_run_metrics with url /metric/v2.0/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}/providers/Microsoft.MachineLearningServices/workspaces/{workspaceName}/runs/{runId}/batch\\n2020-12-22 18:06:26,155|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:26,156|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|Awaiter is BatchTaskQueueAdd_1_Batches\\n2020-12-22 18:06:26,158|azureml.BatchTaskQueueAdd_1_Batches.0__handle_batch.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:26,158|azureml.BatchTaskQueueAdd_1_Batches|DEBUG|\\n2020-12-22 18:06:26,158|azureml.BatchTaskQueueAdd_1_Batches.WaitFlushSource:BatchTaskQueueAdd_1_Batches|DEBUG|[STOP]\\n2020-12-22 18:06:26,296|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.MetricsClient.post_run_metrics-async:False|DEBUG|[STOP]\\n2020-12-22 18:06:28,262|azureml._file_utils.upload|DEBUG|Uploaded blob ExperimentRun/dcid.torchvision_1608659833_6a87102a/outputs/model_latest.pth with size 176430266.\\n2020-12-22 18:06:28,326|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,326|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|Awaiter is upload_files\\n2020-12-22 18:06:28,326|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.upload_files.0_perform_upload.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,326|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.upload_files|DEBUG|Waiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 0.0002868175506591797 seconds.\\nWaiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 0.25058913230895996 seconds.\\nWaiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 0.5009284019470215 seconds.\\nWaiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 0.7512490749359131 seconds.\\nWaiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 1.0015592575073242 seconds.\\nWaiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 1.2518599033355713 seconds.\\nWaiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 1.5021743774414062 seconds.\\nWaiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 1.7524776458740234 seconds.\\nWaiting on task: 0_perform_upload.\\n1 tasks left. Current duration of flush 2.002784013748169 seconds.\\n\\n2020-12-22 18:06:28,326|azureml._SubmittedRun#torchvision_1608659833_6a87102a.RunHistoryFacade.ArtifactsClient.upload_files.WaitFlushSource:upload_files|DEBUG|[STOP]\\n2020-12-22 18:06:28,326|azureml.TrackFolders|DEBUG|[STOP]\\n2020-12-22 18:06:28,326|azureml._history.utils.context_managers|DEBUG|exiting ContentUploader, waiting for file_watcher to finish upload...\\n2020-12-22 18:06:28,326|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher called finish, setting event\\n2020-12-22 18:06:28,326|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher received exit event, getting current_stat\\n2020-12-22 18:06:28,327|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:06:28,327|azureml._history.utils.context_managers.FileWatcher.UploadQueue.22_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:06:28,327|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 22_result to queue of approximate size: 22\\n2020-12-22 18:06:28,327|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher retrieved current_stat, will upload to current_stat\\n2020-12-22 18:06:28,329|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,330|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,330|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,330|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,331|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,331|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,331|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,331|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,332|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,332|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,332|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,332|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,332|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,333|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,333|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,333|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,333|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,333|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,334|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,334|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,334|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,334|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,334|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,335|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,335|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,335|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,335|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,335|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher uploading files to current_stat...\\n2020-12-22 18:06:28,336|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WorkerPool|DEBUG|submitting future: result\\n2020-12-22 18:06:28,337|azureml._history.utils.context_managers.FileWatcher.UploadQueue.23_result|DEBUG|Using basic handler - no exception handling\\n2020-12-22 18:06:28,337|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Adding task 23_result to queue of approximate size: 23\\n2020-12-22 18:06:28,337|azureml._history.utils.context_managers.FileWatcher|DEBUG|FileWatcher finished uploading to current_stat, finishing task queue\\n2020-12-22 18:06:28,337|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|[Stop] - waiting default timeout\\n2020-12-22 18:06:28,337|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[START]\\n2020-12-22 18:06:28,339|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Overriding default flush timeout from None to 120\\n2020-12-22 18:06:28,339|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|Waiting 120 seconds on tasks: [AsyncTask(0_result), AsyncTask(1_result), AsyncTask(2_result), AsyncTask(3_result), AsyncTask(4_result), AsyncTask(5_result), AsyncTask(6_result), AsyncTask(7_result), AsyncTask(8_result), AsyncTask(9_result), AsyncTask(10_result), AsyncTask(11_result), AsyncTask(12_result), AsyncTask(13_result), AsyncTask(14_result), AsyncTask(15_result), AsyncTask(16_result), AsyncTask(17_result), AsyncTask(18_result), AsyncTask(19_result), AsyncTask(20_result), AsyncTask(21_result), AsyncTask(22_result), AsyncTask(23_result)].\\n2020-12-22 18:06:28,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.0_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.1_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.2_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,340|azureml._history.utils.context_managers.FileWatcher.UploadQueue.3_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.4_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.5_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.6_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.6_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.6_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.7_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.7_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.7_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.8_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.8_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.8_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.9_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.9_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.9_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.10_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.10_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.10_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,341|azureml._history.utils.context_managers.FileWatcher.UploadQueue.11_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.11_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.11_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.12_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.12_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.12_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.13_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.13_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.13_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.14_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.14_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.14_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.15_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.15_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.15_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.16_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.16_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.16_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.17_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.17_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.17_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.18_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.18_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,342|azureml._history.utils.context_managers.FileWatcher.UploadQueue.18_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.19_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.19_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.19_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.20_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.20_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.20_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.21_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.21_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.21_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.22_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.22_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,343|azureml._history.utils.context_managers.FileWatcher.UploadQueue.22_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,594|azureml._history.utils.context_managers.FileWatcher.UploadQueue.23_result.WaitingTask|DEBUG|[START]\\n2020-12-22 18:06:28,594|azureml._history.utils.context_managers.FileWatcher.UploadQueue.23_result.WaitingTask|DEBUG|Awaiter is UploadQueue\\n2020-12-22 18:06:28,594|azureml._history.utils.context_managers.FileWatcher.UploadQueue.23_result.WaitingTask|DEBUG|[STOP]\\n2020-12-22 18:06:28,594|azureml._history.utils.context_managers.FileWatcher.UploadQueue|DEBUG|Waiting on task: 23_result.\\n1 tasks left. Current duration of flush 0.003899812698364258 seconds.\\n\\n2020-12-22 18:06:28,594|azureml._history.utils.context_managers.FileWatcher.UploadQueue.WaitFlushSource:UploadQueue|DEBUG|[STOP]\\n\\nRun is completed.\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.17.0\"}, \"loading\": false}"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = exp.submit(estimator)\n",
    "RunDetails(run).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RunId: torchvision_1608659833_6a87102a\n",
      "Web View: https://ml.azure.com/experiments/torchvision/runs/torchvision_1608659833_6a87102a?wsid=/subscriptions/1db0a5ce-7de1-4082-8e25-3c5a4e5a9a98/resourcegroups/ProjektAzure/workspaces/ProjektAzure\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "\n",
      "[2020-12-22T17:57:16.103369] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['train.py', '--data_path', '.', '--workers', '8', '--learning_rate', '0.005', '--epochs', '1', '--anchor_sizes', '16,32,64,128,256,512', '--anchor_aspect_ratios', '0.25,0.5,1.0,2.0', '--rpn_nms_thresh', '0.5', '--box_nms_thresh', '0.3', '--box_score_thresh', '0.1'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 90027\n",
      "Entering Run History Context Manager.\n",
      "[2020-12-22T17:57:19.460100] Current directory: /tmp/azureml_runs/torchvision_1608659833_6a87102a\n",
      "[2020-12-22T17:57:19.460129] Preparing to call script [train.py] with arguments:['--data_path', '.', '--workers', '8', '--learning_rate', '0.005', '--epochs', '1', '--anchor_sizes', '16,32,64,128,256,512', '--anchor_aspect_ratios', '0.25,0.5,1.0,2.0', '--rpn_nms_thresh', '0.5', '--box_nms_thresh', '0.3', '--box_score_thresh', '0.1']\n",
      "[2020-12-22T17:57:19.460145] After variable expansion, calling script [train.py] with arguments:['--data_path', '.', '--workers', '8', '--learning_rate', '0.005', '--epochs', '1', '--anchor_sizes', '16,32,64,128,256,512', '--anchor_aspect_ratios', '0.25,0.5,1.0,2.0', '--rpn_nms_thresh', '0.5', '--box_nms_thresh', '0.3', '--box_score_thresh', '0.1']\n",
      "\n",
      "Epoch: [0]  [  0/279]  eta: 0:10:59  lr: 0.000023  loss: 1.3978 (1.3978)  loss_classifier: 0.5807 (0.5807)  loss_box_reg: 0.0184 (0.0184)  loss_objectness: 0.6910 (0.6910)  loss_rpn_box_reg: 0.1076 (0.1076)  time: 2.3651  data: 0.2674  max mem: 2998\n",
      "Epoch: [0]  [ 10/279]  eta: 0:07:58  lr: 0.000203  loss: 1.3978 (1.3133)  loss_classifier: 0.4714 (0.4253)  loss_box_reg: 0.0191 (0.0310)  loss_objectness: 0.6910 (0.6910)  loss_rpn_box_reg: 0.1534 (0.1659)  time: 1.7795  data: 0.0315  max mem: 4405\n",
      "Epoch: [0]  [ 20/279]  eta: 0:07:29  lr: 0.000382  loss: 1.0759 (1.1483)  loss_classifier: 0.1555 (0.2679)  loss_box_reg: 0.0198 (0.0284)  loss_objectness: 0.6905 (0.6896)  loss_rpn_box_reg: 0.1534 (0.1623)  time: 1.7026  data: 0.0068  max mem: 4405\n",
      "Epoch: [0]  [ 30/279]  eta: 0:07:14  lr: 0.000562  loss: 0.9953 (1.1214)  loss_classifier: 0.0891 (0.2409)  loss_box_reg: 0.0329 (0.0409)  loss_objectness: 0.6842 (0.6857)  loss_rpn_box_reg: 0.1259 (0.1539)  time: 1.7267  data: 0.0061  max mem: 4405\n",
      "Epoch: [0]  [ 40/279]  eta: 0:06:57  lr: 0.000742  loss: 1.0824 (1.1300)  loss_classifier: 0.1540 (0.2355)  loss_box_reg: 0.0869 (0.0645)  loss_objectness: 0.6753 (0.6815)  loss_rpn_box_reg: 0.1209 (0.1486)  time: 1.7607  data: 0.0063  max mem: 4428\n",
      "Epoch: [0]  [ 50/279]  eta: 0:06:41  lr: 0.000921  loss: 1.0258 (1.1078)  loss_classifier: 0.1367 (0.2139)  loss_box_reg: 0.1146 (0.0760)  loss_objectness: 0.6609 (0.6761)  loss_rpn_box_reg: 0.1181 (0.1417)  time: 1.7689  data: 0.0063  max mem: 4428\n",
      "Epoch: [0]  [ 60/279]  eta: 0:06:25  lr: 0.001101  loss: 1.0225 (1.1120)  loss_classifier: 0.1311 (0.2063)  loss_box_reg: 0.1394 (0.1024)  loss_objectness: 0.6333 (0.6657)  loss_rpn_box_reg: 0.1104 (0.1375)  time: 1.7942  data: 0.0063  max mem: 4428\n",
      "Epoch: [0]  [ 70/279]  eta: 0:06:08  lr: 0.001281  loss: 0.9886 (1.0784)  loss_classifier: 0.1251 (0.1911)  loss_box_reg: 0.1633 (0.1059)  loss_objectness: 0.5891 (0.6503)  loss_rpn_box_reg: 0.0997 (0.1311)  time: 1.7804  data: 0.0061  max mem: 4428\n",
      "Epoch: [0]  [ 80/279]  eta: 0:05:52  lr: 0.001460  loss: 0.8383 (1.0542)  loss_classifier: 0.0868 (0.1792)  loss_box_reg: 0.1163 (0.1137)  loss_objectness: 0.5358 (0.6327)  loss_rpn_box_reg: 0.0979 (0.1286)  time: 1.7917  data: 0.0066  max mem: 4428\n",
      "Epoch: [0]  [ 90/279]  eta: 0:05:33  lr: 0.001640  loss: 0.8540 (1.0314)  loss_classifier: 0.0713 (0.1678)  loss_box_reg: 0.1619 (0.1199)  loss_objectness: 0.4565 (0.6123)  loss_rpn_box_reg: 0.1218 (0.1314)  time: 1.7771  data: 0.0065  max mem: 4428\n",
      "Epoch: [0]  [100/279]  eta: 0:05:16  lr: 0.001820  loss: 0.8140 (1.0071)  loss_classifier: 0.0559 (0.1566)  loss_box_reg: 0.1432 (0.1196)  loss_objectness: 0.4434 (0.5997)  loss_rpn_box_reg: 0.1249 (0.1312)  time: 1.7683  data: 0.0118  max mem: 4428\n",
      "Epoch: [0]  [110/279]  eta: 0:04:58  lr: 0.001999  loss: 0.8039 (0.9902)  loss_classifier: 0.0582 (0.1493)  loss_box_reg: 0.1430 (0.1272)  loss_objectness: 0.4418 (0.5828)  loss_rpn_box_reg: 0.1253 (0.1309)  time: 1.7614  data: 0.0121  max mem: 4428\n",
      "Epoch: [0]  [120/279]  eta: 0:04:41  lr: 0.002179  loss: 0.7519 (0.9664)  loss_classifier: 0.0596 (0.1421)  loss_box_reg: 0.1695 (0.1312)  loss_objectness: 0.3700 (0.5629)  loss_rpn_box_reg: 0.1253 (0.1303)  time: 1.7604  data: 0.0065  max mem: 4428\n",
      "Epoch: [0]  [130/279]  eta: 0:04:23  lr: 0.002359  loss: 0.6649 (0.9406)  loss_classifier: 0.0568 (0.1360)  loss_box_reg: 0.1676 (0.1320)  loss_objectness: 0.3026 (0.5406)  loss_rpn_box_reg: 0.1471 (0.1321)  time: 1.7915  data: 0.0063  max mem: 4428\n",
      "Epoch: [0]  [140/279]  eta: 0:04:05  lr: 0.002538  loss: 0.6058 (0.9160)  loss_classifier: 0.0601 (0.1314)  loss_box_reg: 0.1468 (0.1356)  loss_objectness: 0.2149 (0.5154)  loss_rpn_box_reg: 0.1501 (0.1337)  time: 1.7792  data: 0.0065  max mem: 4428\n",
      "Epoch: [0]  [150/279]  eta: 0:03:48  lr: 0.002718  loss: 0.5631 (0.8872)  loss_classifier: 0.0671 (0.1273)  loss_box_reg: 0.1887 (0.1390)  loss_objectness: 0.1276 (0.4875)  loss_rpn_box_reg: 0.1453 (0.1334)  time: 1.8161  data: 0.0068  max mem: 4428\n",
      "Epoch: [0]  [160/279]  eta: 0:03:31  lr: 0.002898  loss: 0.4413 (0.8637)  loss_classifier: 0.0625 (0.1240)  loss_box_reg: 0.1690 (0.1417)  loss_objectness: 0.0892 (0.4635)  loss_rpn_box_reg: 0.1187 (0.1345)  time: 1.8103  data: 0.0066  max mem: 4428\n",
      "Epoch: [0]  [170/279]  eta: 0:03:13  lr: 0.003077  loss: 0.4413 (0.8399)  loss_classifier: 0.0501 (0.1198)  loss_box_reg: 0.1214 (0.1417)  loss_objectness: 0.0892 (0.4432)  loss_rpn_box_reg: 0.1452 (0.1351)  time: 1.7629  data: 0.0064  max mem: 4428\n",
      "Epoch: [0]  [180/279]  eta: 0:02:55  lr: 0.003257  loss: 0.4656 (0.8185)  loss_classifier: 0.0474 (0.1163)  loss_box_reg: 0.1161 (0.1433)  loss_objectness: 0.0821 (0.4242)  loss_rpn_box_reg: 0.1327 (0.1347)  time: 1.7631  data: 0.0065  max mem: 4428\n",
      "Epoch: [0]  [190/279]  eta: 0:02:37  lr: 0.003437  loss: 0.4656 (0.8015)  loss_classifier: 0.0566 (0.1140)  loss_box_reg: 0.1904 (0.1471)  loss_objectness: 0.0808 (0.4060)  loss_rpn_box_reg: 0.1017 (0.1344)  time: 1.7601  data: 0.0072  max mem: 4428\n",
      "Epoch: [0]  [200/279]  eta: 0:02:19  lr: 0.003616  loss: 0.4498 (0.7814)  loss_classifier: 0.0677 (0.1112)  loss_box_reg: 0.1924 (0.1471)  loss_objectness: 0.0566 (0.3889)  loss_rpn_box_reg: 0.1374 (0.1342)  time: 1.7394  data: 0.0072  max mem: 4428\n",
      "Epoch: [0]  [210/279]  eta: 0:02:02  lr: 0.003796  loss: 0.4632 (0.7671)  loss_classifier: 0.0677 (0.1092)  loss_box_reg: 0.1924 (0.1503)  loss_objectness: 0.0649 (0.3746)  loss_rpn_box_reg: 0.1365 (0.1330)  time: 1.7358  data: 0.0068  max mem: 4428\n",
      "Epoch: [0]  [220/279]  eta: 0:01:44  lr: 0.003976  loss: 0.3747 (0.7494)  loss_classifier: 0.0548 (0.1067)  loss_box_reg: 0.1814 (0.1506)  loss_objectness: 0.0688 (0.3608)  loss_rpn_box_reg: 0.0898 (0.1314)  time: 1.7566  data: 0.0068  max mem: 4428\n",
      "Epoch: [0]  [230/279]  eta: 0:01:26  lr: 0.004156  loss: 0.3902 (0.7385)  loss_classifier: 0.0561 (0.1056)  loss_box_reg: 0.1814 (0.1542)  loss_objectness: 0.0627 (0.3476)  loss_rpn_box_reg: 0.1209 (0.1311)  time: 1.8176  data: 0.0070  max mem: 4510\n",
      "Epoch: [0]  [240/279]  eta: 0:01:09  lr: 0.004335  loss: 0.4298 (0.7231)  loss_classifier: 0.0680 (0.1035)  loss_box_reg: 0.1895 (0.1548)  loss_objectness: 0.0511 (0.3353)  loss_rpn_box_reg: 0.1088 (0.1295)  time: 1.8296  data: 0.0072  max mem: 4510\n",
      "Epoch: [0]  [250/279]  eta: 0:00:51  lr: 0.004515  loss: 0.4298 (0.7117)  loss_classifier: 0.0660 (0.1023)  loss_box_reg: 0.2195 (0.1571)  loss_objectness: 0.0463 (0.3238)  loss_rpn_box_reg: 0.0947 (0.1286)  time: 1.8194  data: 0.0069  max mem: 4510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [260/279]  eta: 0:00:33  lr: 0.004695  loss: 0.4049 (0.6976)  loss_classifier: 0.0660 (0.1006)  loss_box_reg: 0.2028 (0.1571)  loss_objectness: 0.0338 (0.3126)  loss_rpn_box_reg: 0.1022 (0.1273)  time: 1.8401  data: 0.0065  max mem: 4510\n",
      "Epoch: [0]  [270/279]  eta: 0:00:16  lr: 0.004874  loss: 0.3912 (0.6892)  loss_classifier: 0.0632 (0.0995)  loss_box_reg: 0.1995 (0.1598)  loss_objectness: 0.0390 (0.3032)  loss_rpn_box_reg: 0.1022 (0.1266)  time: 1.8255  data: 0.0068  max mem: 4510\n",
      "Epoch: [0]  [278/279]  eta: 0:00:01  lr: 0.005000  loss: 0.4043 (0.6818)  loss_classifier: 0.0614 (0.0984)  loss_box_reg: 0.1923 (0.1598)  loss_objectness: 0.0541 (0.2968)  loss_rpn_box_reg: 0.1198 (0.1268)  time: 1.7782  data: 0.0069  max mem: 4510\n",
      "Epoch: [0] Total time: 0:08:16 (1.7787 s / it)\n",
      "creating index...\n",
      "index created!\n",
      "<string>:6: DeprecationWarning: object of type <class 'numpy.float64'> cannot be safely interpreted as an integer.\n",
      "Test:  [ 0/50]  eta: 0:00:59  model_time: 0.9090 (0.9090)  evaluator_time: 0.0083 (0.0083)  time: 1.1835  data: 0.2588  max mem: 4510\n",
      "Test:  [49/50]  eta: 0:00:00  model_time: 0.8107 (0.7965)  evaluator_time: 0.0053 (0.0084)  time: 0.8069  data: 0.0062  max mem: 4510\n",
      "Test: Total time: 0:00:40 (0.8192 s / it)\n",
      "Averaged stats: model_time: 0.8107 (0.7965)  evaluator_time: 0.0053 (0.0084)\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      "IoU metric: bbox\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.529\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.957\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.522\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.217\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.543\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.582\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.479\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.612\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.216\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.629\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.641\n",
      "That's it!\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 90027\n",
      "\n",
      "\n",
      "[2020-12-22T18:06:25.602546] The experiment completed successfully. Finalizing run...\n",
      "[2020-12-22T18:06:25.602570] Start FinalizingInRunHistory\n",
      "[2020-12-22T18:06:25.603185] Logging experiment finalizing status in history service.\n",
      "Cleaning up all outstanding Run operations, waiting 300.0 seconds\n",
      "2 items cleaning up...\n",
      "Cleanup took 0.12555456161499023 seconds\n",
      "[2020-12-22T18:06:29.423551] Finished context manager injector.\n",
      "\n",
      "Execution Summary\n",
      "=================\n",
      "RunId: torchvision_1608659833_6a87102a\n",
      "Web View: https://ml.azure.com/experiments/torchvision/runs/torchvision_1608659833_6a87102a?wsid=/subscriptions/1db0a5ce-7de1-4082-8e25-3c5a4e5a9a98/resourcegroups/ProjektAzure/workspaces/ProjektAzure\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'runId': 'torchvision_1608659833_6a87102a',\n",
       " 'target': 'local',\n",
       " 'status': 'Completed',\n",
       " 'startTimeUtc': '2020-12-22T17:57:15.099082Z',\n",
       " 'endTimeUtc': '2020-12-22T18:06:31.563373Z',\n",
       " 'properties': {'_azureml.ComputeTargetType': 'local',\n",
       "  'ContentSnapshotId': None,\n",
       "  'azureml.git.repository_uri': 'https://github.com/ispmor/azure-project.git',\n",
       "  'mlflow.source.git.repoURL': 'https://github.com/ispmor/azure-project.git',\n",
       "  'azureml.git.branch': 'main',\n",
       "  'mlflow.source.git.branch': 'main',\n",
       "  'azureml.git.commit': '0cd15c57f57b5894818909867bd32604aa9d5ad1',\n",
       "  'mlflow.source.git.commit': '0cd15c57f57b5894818909867bd32604aa9d5ad1',\n",
       "  'azureml.git.dirty': 'True'},\n",
       " 'inputDatasets': [],\n",
       " 'outputDatasets': [],\n",
       " 'runDefinition': {'script': 'train.py',\n",
       "  'useAbsolutePath': False,\n",
       "  'arguments': ['--data_path',\n",
       "   '.',\n",
       "   '--workers',\n",
       "   '8',\n",
       "   '--learning_rate',\n",
       "   '0.005',\n",
       "   '--epochs',\n",
       "   '1',\n",
       "   '--anchor_sizes',\n",
       "   '16,32,64,128,256,512',\n",
       "   '--anchor_aspect_ratios',\n",
       "   '0.25,0.5,1.0,2.0',\n",
       "   '--rpn_nms_thresh',\n",
       "   '0.5',\n",
       "   '--box_nms_thresh',\n",
       "   '0.3',\n",
       "   '--box_score_thresh',\n",
       "   '0.1'],\n",
       "  'sourceDirectoryDataStore': None,\n",
       "  'framework': 'Python',\n",
       "  'communicator': 'None',\n",
       "  'target': 'local',\n",
       "  'dataReferences': {},\n",
       "  'data': {},\n",
       "  'outputData': {},\n",
       "  'jobName': None,\n",
       "  'maxRunDurationSeconds': None,\n",
       "  'nodeCount': 1,\n",
       "  'priority': None,\n",
       "  'credentialPassthrough': False,\n",
       "  'environment': {'name': 'Experiment torchvision Environment',\n",
       "   'version': 'Autosave_2020-12-21T20:57:49Z_6cb444b5',\n",
       "   'python': {'interpreterPath': '/anaconda/envs/azureml_py36_pytorch/bin/python',\n",
       "    'userManagedDependencies': True,\n",
       "    'condaDependencies': {'channels': ['anaconda', 'conda-forge'],\n",
       "     'dependencies': ['python=3.6.2',\n",
       "      {'pip': ['azureml-defaults',\n",
       "        'torch==1.4.0',\n",
       "        'torchvision==0.5.0',\n",
       "        'horovod==0.18.1',\n",
       "        'tensorboard==1.14.0',\n",
       "        'future==0.17.1']}],\n",
       "     'name': 'project_environment'},\n",
       "    'baseCondaEnvironment': None},\n",
       "   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE',\n",
       "    'NCCL_TREE_THRESHOLD': '0'},\n",
       "   'docker': {'baseImage': 'mcr.microsoft.com/azureml/base-gpu:openmpi3.1.2-cuda10.1-cudnn7-ubuntu18.04',\n",
       "    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n",
       "    'baseDockerfile': None,\n",
       "    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n",
       "    'enabled': False,\n",
       "    'arguments': []},\n",
       "   'spark': {'repositories': [], 'packages': [], 'precachePackages': False},\n",
       "   'inferencingStackVersion': None},\n",
       "  'history': {'outputCollection': True,\n",
       "   'directoriesToWatch': ['logs'],\n",
       "   'enableMLflowTracking': True,\n",
       "   'snapshotProject': False},\n",
       "  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n",
       "    'spark.yarn.maxAppAttempts': '1'}},\n",
       "  'parallelTask': {'maxRetriesPerWorker': 0,\n",
       "   'workerCountPerNode': 1,\n",
       "   'terminalExitCodes': None,\n",
       "   'configuration': {}},\n",
       "  'amlCompute': {'name': None,\n",
       "   'vmSize': None,\n",
       "   'retainCluster': False,\n",
       "   'clusterMaxNodeCount': 1},\n",
       "  'aiSuperComputer': {'instanceType': None,\n",
       "   'frameworkImage': None,\n",
       "   'imageVersion': None,\n",
       "   'location': None,\n",
       "   'aiSuperComputerStorageData': None},\n",
       "  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n",
       "  'mpi': {'processCountPerNode': 1},\n",
       "  'hdi': {'yarnDeployMode': 'Cluster'},\n",
       "  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n",
       "  'exposedPorts': None,\n",
       "  'docker': {'useDocker': False,\n",
       "   'sharedVolumes': True,\n",
       "   'shmSize': '2g',\n",
       "   'arguments': []},\n",
       "  'cmk8sCompute': {'configuration': {}},\n",
       "  'commandReturnCodeConfig': {'returnCode': 'Zero',\n",
       "   'successfulReturnCodes': []}},\n",
       " 'logFiles': {'azureml-logs/60_control_log.txt': 'https://projektastorage1d32b8c8a.blob.core.windows.net/azureml/ExperimentRun/dcid.torchvision_1608659833_6a87102a/azureml-logs/60_control_log.txt?sv=2019-02-02&sr=b&sig=eKvZjJXb5R9MR0QMF%2Fd%2ByurgoK6ijzqGvl7ju9zhpPo%3D&st=2020-12-22T17%3A56%3A38Z&se=2020-12-23T02%3A06%3A38Z&sp=r',\n",
       "  'azureml-logs/70_driver_log.txt': 'https://projektastorage1d32b8c8a.blob.core.windows.net/azureml/ExperimentRun/dcid.torchvision_1608659833_6a87102a/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=4mFSFwZS5bkX7ufUMi9TQbOfyy8cGNnAKvfT2DsXE%2Bg%3D&st=2020-12-22T17%3A56%3A38Z&se=2020-12-23T02%3A06%3A38Z&sp=r',\n",
       "  'logs/azureml/90027_azureml.log': 'https://projektastorage1d32b8c8a.blob.core.windows.net/azureml/ExperimentRun/dcid.torchvision_1608659833_6a87102a/logs/azureml/90027_azureml.log?sv=2019-02-02&sr=b&sig=gec%2BhIClYm5eXqDesf11Gl3UjmHmGIFMgUii6CwkSlw%3D&st=2020-12-22T17%3A47%3A22Z&se=2020-12-23T01%3A57%3A22Z&sp=r',\n",
       "  'logs/azureml/dataprep/python_span_745bbe04-4801-4aff-a002-23ebacd7fc9c.jsonl': 'https://projektastorage1d32b8c8a.blob.core.windows.net/azureml/ExperimentRun/dcid.torchvision_1608659833_6a87102a/logs/azureml/dataprep/python_span_745bbe04-4801-4aff-a002-23ebacd7fc9c.jsonl?sv=2019-02-02&sr=b&sig=t99aeNlhGQMNSQaypaXtFtpsf1D5VmvencMznjDk8mQ%3D&st=2020-12-22T17%3A47%3A22Z&se=2020-12-23T01%3A57%3A22Z&sp=r'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azureml-logs/60_control_log.txt',\n",
       " 'azureml-logs/70_driver_log.txt',\n",
       " 'logs/azureml/90027_azureml.log',\n",
       " 'logs/azureml/dataprep/python_span_745bbe04-4801-4aff-a002-23ebacd7fc9c.jsonl',\n",
       " 'outputs/model_latest.pth']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mAP@IoU=0.50': 0.9566988929770025}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now register this first model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(workspace=Workspace.create(name='ProjektAzure', subscription_id='1db0a5ce-7de1-4082-8e25-3c5a4e5a9a98', resource_group='ProjektAzure'), name=torchvision_local_model, id=torchvision_local_model:2, version=2, tags={}, properties={})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.register_model(model_name=\"torchvision_local_model\", model_path=\"/outputs/model_latest.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's download our model and load it to make predictions on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.download_file(\"outputs/model_latest.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "anchor_sizes = \"16,32,64,128,256,512\"\n",
    "anchor_aspect_ratios = \"0.25,0.5,1.0,2.0\"\n",
    "rpn_nms_threshold = 0.5\n",
    "box_nms_threshold = 0.3\n",
    "box_score_threshold = 0.1\n",
    "num_box_detections = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Mask RCNN model\n",
    "model = get_model(\n",
    "    num_classes,\n",
    "    anchor_sizes,\n",
    "    anchor_aspect_ratios,\n",
    "    rpn_nms_threshold,\n",
    "    box_nms_threshold,\n",
    "    box_score_threshold,\n",
    "    num_box_detections,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign()\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): None\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu3): ReLU(inplace=True)\n",
       "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu4): ReLU(inplace=True)\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = \"model_latest.pth\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a random subset of the data to visualize predictions on the images.\n",
    "data_path = \"./scripts\"\n",
    "dataset = BuildDataset(data_path, get_transform(train=False))\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(len(dataset)):\n",
    "#     img, _ = dataset[i]\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         prediction = model([img.to(device)])\n",
    "#     img = Image.fromarray(img.mul(255).permute(1, 2, 0).byte().numpy())\n",
    "#     preds = prediction[0][\"boxes\"].cpu().numpy()\n",
    "#     print(prediction[0][\"scores\"])\n",
    "#     draw = ImageDraw.Draw(img)\n",
    "#     for i in range(len(preds)):\n",
    "#         draw.rectangle(\n",
    "#             ((preds[i][0], preds[i][1]), (preds[i][2], preds[i][3])), outline=\"red\"\n",
    "#         )\n",
    "#     display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook, we  will [build a custom docker image and push it to Azure Container Registry](03_BuildDockerImage.ipynb). This image will be used for tunning the hyperparameters of the model on AzureMLCompute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "maxluk"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "msauthor": "minxia"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
